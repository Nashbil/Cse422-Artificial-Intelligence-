# -*- coding: utf-8 -*-
"""Project_CSE422.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kCDFwjkv-cbaddUbstzKUGLdiwtWzXT4

# ARTIFICIAL INTELLIGENCE  (CSE422)
### Semester: Spring 2025
## Group Project

**Group Number:** 16  
**Group Members:**  
* Syed Momtahin Mahmood, 21101188
* Nabil Nashit, 21201060

**Section:** 07

## Goal
To develop a machine learning-based classification system that can accurately predict the obesity level of individuals based on their personal, behavioral, and lifestyle attributes.

## Dataset
For this project, we will use the dataset provided by **G-Research** from *Kaggle*. This dataset contains more than 2000 rows and 17 columns in the training set.
Since we are to predict the future values of obesity levels and consisting of distinct categories and not continuous values, this is a **Classification Problem**.

## Features
We can see the different features included in the dataset. Specifically, the features included per asset are the following:

* **Age**
Age of the individual.
* **Gender**
	Biological sex: Male or Female.
* **Height**
	Height of the person in meters.
* **Weight**
	Weight of the person in kilograms.
* **CALC**
	Frequency of alcohol consumption (Always, Frequently, Sometimes, No).
* **FAVC**
	Do you frequently consume high-calorie food? (yes or no).
* **FCVC**
Frequency of vegetable consumption (scale from 1 to 3).
* **NCP**
	Number of main meals per day.
* **SCC**
Do you monitor your caloric intake? (yes or no).
* **SMOKE**
Do you smoke? (yes or no).
* **CH2O**
Daily water intake (scale from 1 to 3).
* **family_history_with_overweight**
Is there a family history of overweight? (yes or no).
* **FAF**
	Frequency of physical activity (hours per week).
* **TUE**
	Daily time spent on technology devices (hours).
* **CAEC**
Frequency of eating food between meals (Always, Frequently, Sometimes, No).
* **MTRANS**
Primary mode of transportation (e.g., Public_Transportation, Walking, Automobile, etc.).
* **NObeyesdad**
	Target Label â€“ Obesity classification. E.g., Normal_Weight, Obesity_Type_I, etc.

The first four columns define the Quantitative features. The 6 middle columns are the asset features describing lifestyle, habits, choices, or health status.
The last column is the prediction target, which we will get to later in more detail.

## Evaluation
Since this is a **classification problem**, we will evaluate our machine learning models using the following metrics:

- **Accuracy:** Measures the overall correctness of the model.
- **Precision, Recall, and F1-Score:** Help understand per-class performance, especially in multi-class problems.
- **Confusion Matrix:** Visualizes true vs. predicted labels to show where the model is getting confused.
- **ROC-AUC Score (One-vs-Rest):** Evaluates probabilistic classification performance across multiple classes.

## Workflow
We are going to follow these steps for this project:
1. Import necessary libraries and data
2. Explore the data
3. Visualize the data
4. Deal with missing values
5. Show correlation between assets
6. Feature design
7. Preprocess the data
8. Split the data for training
9. Train machine learning models
10. Evaluate scores

### Dependencies Import


import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn
import plotly

# Data manipulation and preprocessing + Models
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.multiclass import OneVsRestClassifier

#OnevsAll Classifier
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier

# Evaluation
from sklearn.metrics import (
    classification_report,
    accuracy_score,

    precision_score,
    recall_score,
    f1_score,
    confusion_matrix,
    auc,
    roc_auc_score,
    roc_curve,
)

"""### Data Import"""

obesity_dataset = pd.read_csv ('/content/Updated_Obesity_Dataset.csv')

obesity_dataset

"""### Data Exploration"""

obesity_dataset.head(10)

print("Number of Rows:", obesity_dataset.shape[0])
print("Number of Columns:", obesity_dataset.shape[1])

obesity_dataset.info()

obesity_dataset.isnull().sum()

print("Shape before dropping:", obesity_dataset.shape)

obesity_dataset['Gender'].fillna(obesity_dataset['Gender'].mode()[0], inplace=True)
obesity_dataset['family_history_with_overweight'].fillna(obesity_dataset['family_history_with_overweight'].mode()[0], inplace=True)
obesity_dataset['CH2O'].fillna(obesity_dataset['CH2O'].mean(), inplace=True)

print(obesity_dataset.isnull().sum())

print(obesity_dataset.dtypes)
print(obesity_dataset['NObeyesdad'].value_counts())

"""###Encode Binary Categorical Features"""

binary_cols = ['Gender', 'FAVC', 'SCC', 'SMOKE', 'family_history_with_overweight']
le = LabelEncoder()
for col in binary_cols:
    obesity_dataset[col] = le.fit_transform(obesity_dataset[col])

"""##One-Hot Encoded Multi-Class Categorical Columns"""

obesity_dataset = pd.get_dummies(obesity_dataset, columns=['CALC', 'CAEC', 'MTRANS'])

"""###Encode Target Column - Label Encoder"""

y = obesity_dataset ['NObeyesdad']
le_target = LabelEncoder()
y_encoded = le_target.fit_transform(y)

"""##Correlation of all the features"""

df = obesity_dataset.copy()
label_enc = LabelEncoder()

for col in df.columns:
    if df[col].dtype == 'object':
        df[col] = label_enc.fit_transform(df[col])
correlation_matrix = df.corr()

plt.figure(figsize=(14,12))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Matrix of All Features')
plt.show()

"""### Scaling data (Numerical Features) - Standar Scaler"""

numerical_cols = ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']
scaler = StandardScaler()
obesity_dataset[numerical_cols] = scaler.fit_transform(obesity_dataset[numerical_cols])

"""### Train-Test Split Split"""

X = obesity_dataset.drop('NObeyesdad', axis=1)
y = y_encoded  # Already encoded target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

"""## Machine Learning Models
The machine learning models that we are going to use for this project are imported from Scikit-Learn. These are as follows:
1. Neural Network
2. Decision Tree
3. Logistic Regression
4. KNN

##Training Models
Neural Network

Decision Tree

Logistic Regression

KNN
"""

models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "KNN": KNeighborsClassifier(),
    "Decision Tree": DecisionTreeClassifier(),
    "Neural Network": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)
}

trained_models = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    trained_models[name] = model

"""###Prediction on Dataset"""

y_pred = model.predict(X_test)

"""###Calculate Prediction Accuracy"""

accuracies = {}
for name, model in trained_models.items():
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    accuracies[name] = acc
    print(f"{name} Accuracy: {acc:.4f}")

plt.figure(figsize=(8, 5))
plt.bar(accuracies.keys(), accuracies.values(), color='skyblue')
plt.title('Model Accuracy Comparison')
plt.ylabel('Accuracy')
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.show()

"""###Calculate Precision, Recall, and F1 Score"""

model_metrics = []

for name, model in trained_models.items():
    y_pred = model.predict(X_test)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')

    model_metrics.append({
        'Model': name,
        'Precision': precision,
        'Recall': recall,
        'F1 Score': f1
    })

# Convert to DataFrame
metrics_df = pd.DataFrame(model_metrics)
print(metrics_df)

metrics_df.set_index('Model')[['Precision', 'Recall', 'F1 Score']].plot(
    kind='bar', figsize=(10,6), title='Precision, Recall & F1 Score Comparison (Weighted Avg)',
    colormap='Set2'
)
plt.ylabel('Score')
plt.ylim(0, 1)
plt.grid(True, linestyle='--', alpha=0.6)
plt.tight_layout()
plt.show()

"""###Confusion Matrix"""

for name, model in trained_models.items():
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(7, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f'{name} - Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

"""###Calculate ROC & AUC Curve"""

#binarize
y_bin_test = label_binarize(y_test, classes=np.unique(y))
y_bin_train = label_binarize(y_train, classes=np.unique(y))
auc_scores = {}

for name, model in trained_models.items():
    ovr = OneVsRestClassifier(model)
    ovr.fit(X_train, y_bin_train)
    y_score = ovr.predict_proba(X_test)

    roc_auc = roc_auc_score(y_bin_test, y_score, average='macro')  # can use 'macro', 'weighted', 'micro'
    auc_scores[name] = roc_auc

for model, score in auc_scores.items():
    print(f"{model} Average AUC Score: {score:.4f}")

y_bin_train = label_binarize(y_train, classes=np.unique(y))
y_bin_test = label_binarize(y_test, classes=np.unique(y))
n_classes = y_bin_test.shape[1]

plt.figure(figsize=(10, 8))

# Loop over each model
for name, model in trained_models.items():
    ovr = OneVsRestClassifier(model)
    ovr.fit(X_train, y_bin_train)
    y_score = ovr.predict_proba(X_test)

    # Compute ROC curve and AUC for each class, then average
    fpr = dict()
    tpr = dict()
    roc_auc = dict()

    for i in range(n_classes):
        fpr[i], tpr[i], _ = roc_curve(y_bin_test[:, i], y_score[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])

    # Compute macro-average AUC
    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))
    mean_tpr = np.zeros_like(all_fpr)

    for i in range(n_classes):
        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])

    mean_tpr /= n_classes
    macro_auc = auc(all_fpr, mean_tpr)

    # Plot macro-average ROC
    plt.plot(all_fpr, mean_tpr, label=f"{name} (AUC = {macro_auc:.2f})")

plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')

plt.title("ROC Curve Comparison (Multiclass)")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend(loc="lower right")
plt.grid()
plt.show()